{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b708e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from skimage import io, transform, color\n",
    "from skimage.util import view_as_blocks\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import os\n",
    "import io as io_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e4e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "piece_symbols = \"prbnkqPRBNKQ\"\n",
    "model = load_model('chess_fen_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc68843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_array):\n",
    "    downsample_size = 200\n",
    "    square_size = int(downsample_size / 8)\n",
    "\n",
    "    # Check if the image is grayscale (2D array), if so convert it to RGB (3D array)\n",
    "    if len(img_array.shape) == 2:\n",
    "        img_array = color.gray2rgb(img_array)\n",
    "    elif img_array.shape[2] == 4:  # Check for RGBA format and convert to RGB\n",
    "        img_array = color.rgba2rgb(img_array)\n",
    "\n",
    "    # Resize the image\n",
    "    img_resized = transform.resize(img_array, (downsample_size, downsample_size), anti_aliasing=True)\n",
    "\n",
    "    # Split the image into 64 tiles (8x8 grid)\n",
    "    tiles = view_as_blocks(img_resized, block_shape=(square_size, square_size, 3))\n",
    "    return tiles.reshape(64, square_size, square_size, 3)\n",
    "\n",
    "\n",
    "def predictions_to_fen(predictions):\n",
    "    fen_string = \"\"\n",
    "    for row in predictions.reshape(8, 8, -1):\n",
    "        empty_count = 0\n",
    "        for square in row:\n",
    "            piece_index = np.argmax(square)\n",
    "            if piece_index == 12:  # Empty square\n",
    "                empty_count += 1\n",
    "            else:\n",
    "                if empty_count > 0:\n",
    "                    fen_string += str(empty_count)\n",
    "                    empty_count = 0\n",
    "                fen_string += piece_symbols[piece_index]\n",
    "        if empty_count > 0:\n",
    "            fen_string += str(empty_count)\n",
    "        fen_string += '/'\n",
    "    return fen_string.rstrip('/')  # Replace slashes with dashes if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19dc633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c773e2ca8b246188caa41a9834e2ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f75f49ac0424a5fa072e4a544c2636c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "def handle_upload(change):\n",
    "    uploaded_file = change['new'][0]  # Get image\n",
    "    if uploaded_file is not None:\n",
    "        image_data = uploaded_file['content']\n",
    "        img = Image.open(io_lib.BytesIO(image_data))\n",
    "        display_size = (100, 100)  \n",
    "        display_img = img.resize(display_size)\n",
    "\n",
    "        # RGBA to RGB\n",
    "        if img.mode == 'RGBA':\n",
    "            img = img.convert('RGB')\n",
    "    \n",
    "        # Convert PIL Image to np array\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Process the image and make a prediction\n",
    "        processed_image = process_image(img_array)  \n",
    "        processed_image = processed_image.reshape(-1, 25, 25, 3)  # Flatten the squares for prediction\n",
    "        predictions = model.predict(processed_image)\n",
    "        fen = predictions_to_fen(predictions)  # Convert predictions to FEN\n",
    "\n",
    "        # Display\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            display(img)\n",
    "            print(\"Predicted FEN:\", fen)\n",
    "\n",
    "# upload button\n",
    "upload_button = widgets.FileUpload(accept='image/*', multiple=False)\n",
    "upload_button.observe(handle_upload, names='value')\n",
    "\n",
    "# Output\n",
    "output = widgets.Output()\n",
    "\n",
    "display(upload_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14c495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
